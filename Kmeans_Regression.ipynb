{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import math\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster0_df = pd.read_csv('C:\\\\ADS\\\\LendingClubData\\\\loan_data\\\\Kmeans_Cluster_0.csv',low_memory=False)\n",
    "cluster1_df = pd.read_csv('C:\\\\ADS\\\\LendingClubData\\\\loan_data\\\\Kmeans_Cluster_1.csv',low_memory=False)\n",
    "cluster2_df = pd.read_csv('C:\\\\ADS\\\\LendingClubData\\\\loan_data\\\\Kmeans_Cluster_2.csv',low_memory=False)\n",
    "cluster3_df = pd.read_csv('C:\\\\ADS\\\\LendingClubData\\\\loan_data\\\\Kmeans_Cluster_3.csv',low_memory=False)\n",
    "cluster4_df = pd.read_csv('C:\\\\ADS\\\\LendingClubData\\\\loan_data\\\\Kmeans_Cluster_4.csv',low_memory=False)\n",
    "cluster5_df = pd.read_csv('C:\\\\ADS\\\\LendingClubData\\\\loan_data\\\\Kmeans_Cluster_5.csv',low_memory=False)\n",
    "cluster6_df = pd.read_csv('C:\\\\ADS\\\\LendingClubData\\\\loan_data\\\\Kmeans_Cluster_6.csv',low_memory=False)\n",
    "cluster7_df = pd.read_csv('C:\\\\ADS\\\\LendingClubData\\\\loan_data\\\\Kmeans_Cluster_7.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_df_list=[cluster0_df,cluster1_df,cluster2_df,cluster3_df,cluster4_df,cluster5_df,cluster6_df,cluster7_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Linear Regression\n",
      "MAE is  0.675709785953\n",
      "RMSE is  0.9054763935667374\n",
      "MAPE is  4.87691755718\n",
      "Training score is  0.954563167493\n",
      "Testing score is  0.95513964834\n",
      "Starting Linear Regression\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7cdc07f6e659>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Starting Linear Regression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mlr_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"MAE is \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_predictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\prshk\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    507\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_residues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msingular_\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 509\u001b[1;33m                 \u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstsq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    510\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\prshk\\Anaconda3\\lib\\site-packages\\scipy\\linalg\\basic.py\u001b[0m in \u001b[0;36mlstsq\u001b[1;34m(a, b, cond, overwrite_a, overwrite_b, check_finite, lapack_driver)\u001b[0m\n\u001b[0;32m   1026\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m                 x, s, rank, info = lapack_func(a1, b1, lwork,\n\u001b[1;32m-> 1028\u001b[1;33m                                                iwork, cond, False, False)\n\u001b[0m\u001b[0;32m   1029\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# complex data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m                 lwork, rwork, iwork = _compute_lwork(lapack_lwork, m, n,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for df in cluster_df_list:\n",
    "    df = df[df['int_rate'].notnull()]\n",
    "    x_set = df.drop(['int_rate'], axis=1)\n",
    "    y_set = df['int_rate']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_set, y_set, random_state=0)\n",
    "    print(\"Starting Linear Regression\")\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(x_train, y_train)\n",
    "    lr_predictions = lr.predict(x_test)\n",
    "    print(\"MAE is \",mean_absolute_error(y_test, lr_predictions))\n",
    "    print(\"RMSE is \",math.sqrt(mean_squared_error(y_test, lr_predictions)))\n",
    "    print(\"MAPE is \",mean_absolute_percentage_error(y_test, lr_predictions))\n",
    "    print(\"Training score is \",lr.score(x_train, y_train))\n",
    "    print(\"Testing score is \",lr.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Random Forrest Regression\n",
      "MAE is  0.701227975929\n",
      "RMSE is  0.968769181487455\n",
      "MAPE is  5.05974856909\n",
      "Training score is  0.990961954233\n",
      "Testing score is  0.948648984322\n",
      "Starting Random Forrest Regression\n",
      "MAE is  0.568818434176\n",
      "RMSE is  0.7970705976942711\n",
      "MAPE is  4.82396289522\n",
      "Training score is  0.992619672971\n",
      "Testing score is  0.958736181484\n",
      "Starting Random Forrest Regression\n",
      "MAE is  0.754311049724\n",
      "RMSE is  1.0571494205748453\n",
      "MAPE is  4.91833062459\n",
      "Training score is  0.988481083999\n",
      "Testing score is  0.936460428431\n",
      "Starting Random Forrest Regression\n",
      "MAE is  0.604582408965\n",
      "RMSE is  0.8480521926332745\n",
      "MAPE is  4.93922845658\n",
      "Training score is  0.992063886075\n",
      "Testing score is  0.955145258341\n",
      "Starting Random Forrest Regression\n",
      "MAE is  0.744900098837\n",
      "RMSE is  1.0357151945540344\n",
      "MAPE is  5.07327108634\n",
      "Training score is  0.989709456142\n",
      "Testing score is  0.942889220337\n",
      "Starting Random Forrest Regression\n",
      "MAE is  0.639978811214\n",
      "RMSE is  0.8915710373233912\n",
      "MAPE is  4.96528174561\n",
      "Training score is  0.991728173368\n",
      "Testing score is  0.953285599401\n",
      "Starting Random Forrest Regression\n",
      "MAE is  0.557382941572\n",
      "RMSE is  0.791836960275808\n",
      "MAPE is  4.66003050071\n",
      "Training score is  0.992929081735\n",
      "Testing score is  0.960791487653\n",
      "Starting Random Forrest Regression\n",
      "MAE is  0.29464556962\n",
      "RMSE is  0.7538734061615259\n",
      "MAPE is  1.94720122727\n",
      "Training score is  0.985738790208\n",
      "Testing score is  0.965302251038\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for df in cluster_df_list:\n",
    "    df = df[df['int_rate'].notnull()]\n",
    "    x_set = df.drop(['int_rate'], axis=1)\n",
    "    y_set = df['int_rate']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_set, y_set, random_state=0)\n",
    "    print(\"Starting Random Forrest Regression\")\n",
    "    rfr = RandomForestRegressor(n_jobs=2)\n",
    "    rfr.fit(x_train, y_train)\n",
    "    joblib.dump(rfr,'C:\\\\ADS\\\\LendingClubData\\\\loan_data\\\\k_best_model_'+str(count)+'.pkl')\n",
    "    rfr_predictions = rfr.predict(x_test)\n",
    "    print(\"MAE is \",mean_absolute_error(y_test, rfr_predictions))\n",
    "    print(\"RMSE is \",math.sqrt(mean_squared_error(y_test, rfr_predictions)))\n",
    "    print(\"MAPE is \",mean_absolute_percentage_error(y_test, rfr_predictions))\n",
    "    print(\"Training score is \",rfr.score(x_train, y_train))\n",
    "    print(\"Testing score is \",rfr.score(x_test, y_test))\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in cluster_df_list:\n",
    "    df = df[df['int_rate'].notnull()]\n",
    "    x_set = df.drop(['int_rate'], axis=1)\n",
    "    y_set = df['int_rate']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_set, y_set, random_state=0)\n",
    "    x_train = StandardScaler().fit_transform(x_train)\n",
    "    x_test = StandardScaler().fit_transform(x_test)\n",
    "    print(\"Starting KNN Regression\")\n",
    "    knn = KNeighborsRegressor(n_neighbors=9)\n",
    "    knn.fit(x_train,y_train.values.ravel())\n",
    "    knn_predictions = knn.predict(x_test)\n",
    "    print(\"MAE is \",mean_absolute_error(y_test, knn_predictions))\n",
    "    print(\"RMSE is \",math.sqrt(mean_squared_error(y_test, knn_predictions)))\n",
    "    print(\"MAPE is \",mean_absolute_percentage_error(y_test, knn_predictions))\n",
    "    print(\"Training score is \",knn.score(x_train, y_train))\n",
    "    print(\"Testing score is \",knn.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in cluster_df_list:\n",
    "    df = df[df['int_rate'].notnull()]\n",
    "    x_set = df.drop(['int_rate'], axis=1)\n",
    "    y_set = df['int_rate']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_set, y_set, random_state=0)\n",
    "    x_train = StandardScaler().fit_transform(x_train)\n",
    "    x_test = StandardScaler().fit_transform(x_test)\n",
    "    print(\"Starting MLP Regression\")\n",
    "    mlp = MLPRegressor(solver='lbfgs', hidden_layer_sizes=50,\n",
    "                               max_iter=150, shuffle=True, random_state=1)\n",
    "    mlp.fit(x_train, y_train)\n",
    "    mlp_predictions = mlp.predict(x_test)\n",
    "    print(\"MAE is \",mean_absolute_error(y_test, mlp_predictions))\n",
    "    print(\"RMSE is \",math.sqrt(mean_squared_error(y_test, mlp_predictions)))\n",
    "    print(\"MAPE is \",mean_absolute_percentage_error(y_test, mlp_predictions))\n",
    "    print(\"Training score is \",mlp.score(x_train, y_train))\n",
    "    print(\"Testing score is \",mlp.score(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
